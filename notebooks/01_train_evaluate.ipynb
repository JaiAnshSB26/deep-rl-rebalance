{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43fc95db",
   "metadata": {},
   "source": [
    "# Deep RL for Multi-Asset Portfolio Rebalancing\n",
    "\n",
    "## Complete Training and Evaluation Pipeline\n",
    "\n",
    "This notebook implements the full pipeline:\n",
    "1. Data download and feature engineering\n",
    "2. PPO training with validation-based model selection\n",
    "3. Evaluation on held-out test set\n",
    "4. Baseline comparisons (5 strategies)\n",
    "5. Statistical tests (Diebold-Mariano, bootstrap CI)\n",
    "6. Sensitivity analysis (cost and risk parameter sweeps)\n",
    "7. Comprehensive visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acd96b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports successful!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add parent directory to path\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import json\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "print(\"Imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3d03df",
   "metadata": {},
   "source": [
    "## 1. Load Configuration and Set Seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e92d0965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch seed set to 42\n",
      "\n",
      "Configuration loaded:\n",
      "  Assets: ['SPY', 'QQQ', 'IWM', 'EFA', 'EEM', 'TLT', 'HYG', 'GLD', 'DBC']\n",
      "  Training period: ['2012-01-01', '2018-12-31']\n",
      "  Validation period: ['2019-01-01', '2021-12-31']\n",
      "  Test period: ['2022-01-01', '2025-10-31']\n",
      "  Transaction cost: 25 bps per turnover\n",
      "  Algorithm: PPO\n"
     ]
    }
   ],
   "source": [
    "# Load config\n",
    "with open('../config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "seed = config['seed']\n",
    "np.random.seed(seed)\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    torch.manual_seed(seed)\n",
    "    print(f\"PyTorch seed set to {seed}\")\n",
    "except ImportError:\n",
    "    print(\"PyTorch not installed, skipping torch seed\")\n",
    "\n",
    "print(f\"\\nConfiguration loaded:\")\n",
    "print(f\"  Assets: {config['assets']}\")\n",
    "print(f\"  Training period: {config['date']['train']}\")\n",
    "print(f\"  Validation period: {config['date']['valid']}\")\n",
    "print(f\"  Test period: {config['date']['test']}\")\n",
    "print(f\"  Transaction cost: {config['trade']['cost_bps_per_turnover']} bps per turnover\")\n",
    "print(f\"  Algorithm: {config['rl']['algo']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1620e52",
   "metadata": {},
   "source": [
    "## 2. Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ecf4255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 10 tickers from 2012-01-01 to 2025-10-31...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:data.download:Loading SPY from cache: data\\raw\\SPY.parquet\n",
      "INFO:data.download:Cached data for SPY doesn't cover range, re-downloading\n",
      "INFO:data.download:Downloading SPY from 2012-01-01 to 2025-10-31\n",
      "INFO:data.download:Cached SPY to data\\raw\\SPY.parquet\n",
      "INFO:data.download:Loading QQQ from cache: data\\raw\\QQQ.parquet\n",
      "INFO:data.download:Cached data for QQQ doesn't cover range, re-downloading\n",
      "INFO:data.download:Downloading QQQ from 2012-01-01 to 2025-10-31\n",
      "INFO:data.download:Cached QQQ to data\\raw\\QQQ.parquet\n",
      "INFO:data.download:Loading IWM from cache: data\\raw\\IWM.parquet\n",
      "INFO:data.download:Cached data for IWM doesn't cover range, re-downloading\n",
      "INFO:data.download:Downloading IWM from 2012-01-01 to 2025-10-31\n",
      "INFO:data.download:Cached IWM to data\\raw\\IWM.parquet\n",
      "INFO:data.download:Loading EFA from cache: data\\raw\\EFA.parquet\n",
      "INFO:data.download:Cached data for EFA doesn't cover range, re-downloading\n",
      "INFO:data.download:Downloading EFA from 2012-01-01 to 2025-10-31\n",
      "INFO:data.download:Cached EFA to data\\raw\\EFA.parquet\n",
      "INFO:data.download:Loading EEM from cache: data\\raw\\EEM.parquet\n",
      "INFO:data.download:Cached data for EEM doesn't cover range, re-downloading\n",
      "INFO:data.download:Downloading EEM from 2012-01-01 to 2025-10-31\n",
      "INFO:data.download:Cached EEM to data\\raw\\EEM.parquet\n",
      "INFO:data.download:Loading TLT from cache: data\\raw\\TLT.parquet\n",
      "INFO:data.download:Cached data for TLT doesn't cover range, re-downloading\n",
      "INFO:data.download:Downloading TLT from 2012-01-01 to 2025-10-31\n",
      "INFO:data.download:Cached TLT to data\\raw\\TLT.parquet\n",
      "INFO:data.download:Loading HYG from cache: data\\raw\\HYG.parquet\n",
      "INFO:data.download:Cached data for HYG doesn't cover range, re-downloading\n",
      "INFO:data.download:Downloading HYG from 2012-01-01 to 2025-10-31\n",
      "INFO:data.download:Cached HYG to data\\raw\\HYG.parquet\n",
      "INFO:data.download:Loading GLD from cache: data\\raw\\GLD.parquet\n",
      "INFO:data.download:Cached data for GLD doesn't cover range, re-downloading\n",
      "INFO:data.download:Downloading GLD from 2012-01-01 to 2025-10-31\n",
      "INFO:data.download:Cached GLD to data\\raw\\GLD.parquet\n",
      "INFO:data.download:Loading DBC from cache: data\\raw\\DBC.parquet\n",
      "INFO:data.download:Cached data for DBC doesn't cover range, re-downloading\n",
      "INFO:data.download:Downloading DBC from 2012-01-01 to 2025-10-31\n",
      "INFO:data.download:Cached DBC to data\\raw\\DBC.parquet\n",
      "INFO:data.download:Loading ^VIX from cache: data\\raw\\_VIX.parquet\n",
      "INFO:data.download:Cached data for ^VIX doesn't cover range, re-downloading\n",
      "INFO:data.download:Downloading ^VIX from 2012-01-01 to 2025-10-31\n",
      "INFO:data.download:Cached ^VIX to data\\raw\\_VIX.parquet\n",
      "INFO:data.download:Successfully loaded 10 out of 10 tickers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloaded 10 tickers successfully:\n",
      "  SPY: 3478 days (2012-01-03 to 2025-10-30)\n",
      "  QQQ: 3478 days (2012-01-03 to 2025-10-30)\n",
      "  IWM: 3478 days (2012-01-03 to 2025-10-30)\n",
      "  EFA: 3478 days (2012-01-03 to 2025-10-30)\n",
      "  EEM: 3478 days (2012-01-03 to 2025-10-30)\n",
      "  TLT: 3478 days (2012-01-03 to 2025-10-30)\n",
      "  HYG: 3478 days (2012-01-03 to 2025-10-30)\n",
      "  GLD: 3478 days (2012-01-03 to 2025-10-30)\n",
      "  DBC: 3478 days (2012-01-03 to 2025-10-30)\n",
      "  ^VIX: 3478 days (2012-01-03 to 2025-10-30)\n"
     ]
    }
   ],
   "source": [
    "from data.download import fetch_ohlcv\n",
    "\n",
    "tickers = config['assets'] + config['exogenous']\n",
    "start_date = config['date']['train'][0]\n",
    "end_date = config['date']['test'][1]\n",
    "\n",
    "print(f\"Downloading {len(tickers)} tickers from {start_date} to {end_date}...\")\n",
    "data = fetch_ohlcv(tickers, start_date, end_date)\n",
    "\n",
    "print(f\"\\nDownloaded {len(data)} tickers successfully:\")\n",
    "for ticker, df in data.items():\n",
    "    print(f\"  {ticker}: {len(df)} days ({df.index.min().date()} to {df.index.max().date()})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55538b7f",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3a98251",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:data.features:Engineering features for 9 assets with execution: next_open\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering features (causal, cross-sectionally normalized)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:data.features:Applying cross-sectional winsorization and z-scoring\n",
      "INFO:data.features:Feature engineering complete: 31302 observations, 18 features\n",
      "INFO:data.features:Return matrix shape: (3478, 9)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature matrix shape: (31302, 18)\n",
      "Return matrix shape: (3478, 9)\n",
      "\n",
      "Feature columns (18):\n",
      "['ret_lag1', 'ret_lag2', 'ret_lag5', 'roll_mean_5', 'roll_mean_21', 'roll_mean_63', 'roll_std_5', 'roll_std_21', 'roll_std_63', 'rsi', 'macd', 'macd_signal', 'macd_hist', 'bb_pct', 'atr_norm', '^VIX_level', '^VIX_chg5', 'market_ret_lag1']\n",
      "\n",
      "Sample features (first date, first asset):\n",
      "                  ret_lag1  ret_lag2  ret_lag5  roll_mean_5  roll_mean_21  \\\n",
      "date       asset                                                            \n",
      "2012-01-03 SPY         0.0       0.0       0.0          0.0           0.0   \n",
      "\n",
      "                  roll_mean_63  roll_std_5  roll_std_21  roll_std_63  rsi  \\\n",
      "date       asset                                                            \n",
      "2012-01-03 SPY             0.0         0.0          0.0          0.0  0.0   \n",
      "\n",
      "                  macd  macd_signal  macd_hist  bb_pct  atr_norm  ^VIX_level  \\\n",
      "date       asset                                                               \n",
      "2012-01-03 SPY     0.0          0.0        0.0     0.0       0.0         0.0   \n",
      "\n",
      "                  ^VIX_chg5  market_ret_lag1  \n",
      "date       asset                              \n",
      "2012-01-03 SPY          0.0              0.0  \n"
     ]
    }
   ],
   "source": [
    "from data.features import engineer_features\n",
    "\n",
    "# Separate asset and exogenous data\n",
    "asset_data = {k: v for k, v in data.items() if k in config['assets']}\n",
    "exog_data = {k: v for k, v in data.items() if k in config['exogenous']}\n",
    "\n",
    "print(\"Engineering features (causal, cross-sectionally normalized)...\")\n",
    "X, R = engineer_features(asset_data, exog_data, config)\n",
    "\n",
    "print(f\"\\nFeature matrix shape: {X.shape}\")\n",
    "print(f\"Return matrix shape: {R.shape}\")\n",
    "print(f\"\\nFeature columns ({len(X.columns)}):\")\n",
    "print(list(X.columns))\n",
    "\n",
    "# Display sample\n",
    "print(\"\\nSample features (first date, first asset):\")\n",
    "print(X.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05662275",
   "metadata": {},
   "source": [
    "## 4. Create Train/Valid/Test Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36f42c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:data.splits:Splits created and saved to ../data/splits.json\n",
      "INFO:data.splits:Train: 1760 days (2012-01-03 to 2018-12-31)\n",
      "INFO:data.splits:Valid: 757 days (2019-01-02 to 2021-12-31)\n",
      "INFO:data.splits:Test: 961 days (2022-01-03 to 2025-10-30)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Split shapes:\n",
      "  Train: X=(1760, 9, 18), R=(1760, 9)\n",
      "  Valid: X=(757, 9, 18), R=(757, 9)\n",
      "  Test:  X=(961, 9, 18), R=(961, 9)\n"
     ]
    }
   ],
   "source": [
    "from data.splits import make_splits, get_split_data\n",
    "\n",
    "dates = X.index.get_level_values('date').unique()\n",
    "splits = make_splits(dates, config, save_path='../data/splits.json')\n",
    "\n",
    "# Extract split data\n",
    "X_train, R_train, dates_train = get_split_data(X, R, splits['train'], config['assets'])\n",
    "X_valid, R_valid, dates_valid = get_split_data(X, R, splits['valid'], config['assets'])\n",
    "X_test, R_test, dates_test = get_split_data(X, R, splits['test'], config['assets'])\n",
    "\n",
    "print(f\"\\nSplit shapes:\")\n",
    "print(f\"  Train: X={X_train.shape}, R={R_train.shape}\")\n",
    "print(f\"  Valid: X={X_valid.shape}, R={R_valid.shape}\")\n",
    "print(f\"  Test:  X={X_test.shape}, R={R_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011efb2e",
   "metadata": {},
   "source": [
    "## 5. Create Environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bd1c03a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:envs.portfolio_env:PortfolioEnv initialized: T=1760, N=9, F=18, obs_dim=175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training environment created:\n",
      "  Observation space: (175,)\n",
      "  Action space: (9,)\n",
      "  Episode length: 1760 days\n",
      "  Transaction cost: 25.00 bps per turnover\n"
     ]
    }
   ],
   "source": [
    "from envs.portfolio_env import PortfolioEnv, rollout_policy\n",
    "\n",
    "# Training environment\n",
    "env_train = PortfolioEnv(X_train, R_train, dates_train, config)\n",
    "\n",
    "print(f\"Training environment created:\")\n",
    "print(f\"  Observation space: {env_train.observation_space.shape}\")\n",
    "print(f\"  Action space: {env_train.action_space.shape}\")\n",
    "print(f\"  Episode length: {env_train.T} days\")\n",
    "print(f\"  Transaction cost: {env_train.cost_rate*10000:.2f} bps per turnover\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7889b10f",
   "metadata": {},
   "source": [
    "## 6. Train PPO Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2a0922e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FOUND EXISTING TRAINED MODEL - SKIPPING TRAINING\n",
      "================================================================================\n",
      "Using existing model: ../results/logs/ppo\\best_model_sharpe_1.3160.zip\n",
      "\n",
      "To retrain from scratch, delete files in: {log_dir}\n"
     ]
    }
   ],
   "source": [
    "from agents.ppo_trainer import train_ppo\n",
    "import glob\n",
    "\n",
    "# Validation evaluation function\n",
    "def eval_fn(policy):\n",
    "    \"\"\"Rollout policy on validation set.\"\"\"\n",
    "    return rollout_policy(policy, X_valid, R_valid, dates_valid, config, deterministic=True)\n",
    "\n",
    "# Check if a trained model already exists\n",
    "log_dir = \"../results/logs/ppo\"\n",
    "existing_models = glob.glob(f\"{log_dir}/best_model_sharpe_*.zip\")\n",
    "\n",
    "if existing_models:\n",
    "    # Use the best existing model (highest Sharpe in filename)\n",
    "    best_model_path = max(existing_models, key=lambda p: float(p.split('_')[-1].replace('.zip', '')))\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"FOUND EXISTING TRAINED MODEL - SKIPPING TRAINING\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Using existing model: {best_model_path}\")\n",
    "    print(\"\\nTo retrain from scratch, delete files in: {log_dir}\")\n",
    "else:\n",
    "    # Train PPO\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"TRAINING PPO AGENT\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    best_model_path = train_ppo(env_train, eval_fn, config, log_dir=log_dir)\n",
    "    print(f\"\\nBest model saved to: {best_model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9106d3",
   "metadata": {},
   "source": [
    "## 7. Evaluate RL Agent on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1524f5dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading best PPO model...\n",
      "Model path: ../results/logs/ppo\\best_model_sharpe_1.3160.zip\n",
      "Model path type: <class 'str'>\n",
      "Loading from: ../results/logs/ppo\\best_model_sharpe_1.3160.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:envs.portfolio_env:PortfolioEnv initialized: T=961, N=9, F=18, obs_dim=175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test set...\n",
      "\n",
      "RL Test Performance:\n",
      "  Days: 960\n",
      "  Mean daily return: 0.0168%\n",
      "  Daily vol: 0.8134%\n",
      "  Avg turnover: 4.21%\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "\n",
    "# Load best model\n",
    "print(\"Loading best PPO model...\")\n",
    "print(f\"Model path: {best_model_path}\")\n",
    "print(f\"Model path type: {type(best_model_path)}\")\n",
    "\n",
    "# Ensure it's a string\n",
    "if best_model_path is None:\n",
    "    raise ValueError(\"No model was saved during training! Check if validation ran successfully.\")\n",
    "\n",
    "model_path_str = str(best_model_path)\n",
    "print(f\"Loading from: {model_path_str}\")\n",
    "\n",
    "ppo_model = PPO.load(model_path_str)\n",
    "\n",
    "# Rollout on test set\n",
    "print(\"Evaluating on test set...\")\n",
    "rl_results = rollout_policy(ppo_model, X_test, R_test, dates_test, config, deterministic=True)\n",
    "\n",
    "print(f\"\\nRL Test Performance:\")\n",
    "print(f\"  Days: {len(rl_results['daily_returns'])}\")\n",
    "print(f\"  Mean daily return: {np.mean(rl_results['daily_returns'])*100:.4f}%\")\n",
    "print(f\"  Daily vol: {np.std(rl_results['daily_returns'], ddof=1)*100:.4f}%\")\n",
    "print(f\"  Avg turnover: {np.mean(rl_results['turnover'])*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b74c383",
   "metadata": {},
   "source": [
    "## 8. Run All Baselines on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f1f5e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "RUNNING BASELINES ON TEST SET\n",
      "================================================================================\n",
      "\n",
      "1. Equal Weight Buy & Hold...\n",
      "2. Periodic Rebalance...\n",
      "3. Risk Parity...\n",
      "4. Momentum Tilt...\n",
      "5. Mean-Variance...\n",
      "\n",
      "All baselines complete!\n"
     ]
    }
   ],
   "source": [
    "from baselines import equal_weights, periodic_rebalance, risk_parity, momentum_tilt, mean_variance\n",
    "\n",
    "baseline_results = {}\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RUNNING BASELINES ON TEST SET\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Equal Weight Buy & Hold\n",
    "print(\"\\n1. Equal Weight Buy & Hold...\")\n",
    "baseline_results['EW_BuyHold'] = equal_weights.run_strategy(X_test, R_test, dates_test, config)\n",
    "\n",
    "# Periodic Rebalance\n",
    "print(\"2. Periodic Rebalance...\")\n",
    "baseline_results['Periodic_Rebal'] = periodic_rebalance.run_strategy(X_test, R_test, dates_test, config)\n",
    "\n",
    "# Risk Parity\n",
    "print(\"3. Risk Parity...\")\n",
    "baseline_results['Risk_Parity'] = risk_parity.run_strategy(X_test, R_test, dates_test, config)\n",
    "\n",
    "# Momentum Tilt\n",
    "print(\"4. Momentum Tilt...\")\n",
    "baseline_results['Momentum'] = momentum_tilt.run_strategy(X_test, R_test, dates_test, config)\n",
    "\n",
    "# Mean-Variance\n",
    "print(\"5. Mean-Variance...\")\n",
    "baseline_results['MeanVar'] = mean_variance.run_strategy(X_test, R_test, dates_test, config)\n",
    "\n",
    "print(\"\\nAll baselines complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dabf009",
   "metadata": {},
   "source": [
    "## 9. Compute Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8359429f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "PERFORMANCE SUMMARY (TEST SET)\n",
      "================================================================================\n",
      "                Sharpe    CAGR  Volatility  Sortino  Calmar  Max_Drawdown  \\\n",
      "PPO_RL          0.3284  0.0347      0.1291   0.4588  0.1192        0.2907   \n",
      "EW_BuyHold      0.5492  0.0619      0.1230   0.7853  0.2907        0.2128   \n",
      "Periodic_Rebal  0.5072  0.0573      0.1252   0.7274  0.2603        0.2199   \n",
      "Risk_Parity     0.4846  0.0495      0.1128   0.6989  0.2292        0.2159   \n",
      "Momentum        0.4004  0.0428      0.1239   0.5735  0.1850        0.2316   \n",
      "MeanVar         0.2858  0.0259      0.1113   0.4001  0.1188        0.2185   \n",
      "\n",
      "                Tail_Ratio  Annualized_Turnover  Cost_Drag_bps     HHI  \n",
      "PPO_RL              0.9175              10.6000       264.9998  0.1666  \n",
      "EW_BuyHold          0.9170               0.0000         0.0000  0.1148  \n",
      "Periodic_Rebal      0.9539               0.1500         3.7490  0.1112  \n",
      "Risk_Parity         0.9501               1.3725        34.3134  0.1325  \n",
      "Momentum            0.9394               3.6048        90.1201  0.1155  \n",
      "MeanVar             1.0008               1.1560        28.8999  0.1529  \n",
      "\n",
      "Saved to results/test_performance_summary.csv\n"
     ]
    }
   ],
   "source": [
    "from metrics.evaluate import full_evaluation\n",
    "\n",
    "# Collect all results\n",
    "all_results = {\n",
    "    'PPO_RL': rl_results,\n",
    "    **baseline_results\n",
    "}\n",
    "\n",
    "# Compute metrics\n",
    "metrics_summary = {}\n",
    "for name, results in all_results.items():\n",
    "    metrics_summary[name] = full_evaluation(results)\n",
    "\n",
    "# Create summary DataFrame\n",
    "df_metrics = pd.DataFrame(metrics_summary).T\n",
    "\n",
    "# Reorder columns\n",
    "cols_order = ['Sharpe', 'CAGR', 'Volatility', 'Sortino', 'Calmar', \n",
    "              'Max_Drawdown', 'Tail_Ratio', 'Annualized_Turnover', 'Cost_Drag_bps', 'HHI']\n",
    "df_metrics = df_metrics[cols_order]\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PERFORMANCE SUMMARY (TEST SET)\")\n",
    "print(\"=\"*80)\n",
    "print(df_metrics.round(4))\n",
    "\n",
    "# Save to CSV\n",
    "df_metrics.to_csv('../results/test_performance_summary.csv')\n",
    "print(\"\\nSaved to results/test_performance_summary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48205f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking baseline results...\n",
      "\n",
      "EW_BuyHold:\n",
      "  Shape: (960,)\n",
      "  Has NaN: False\n",
      "  Has Inf: False\n",
      "  Min: -0.040646\n",
      "  Max: 0.059543\n",
      "  Mean: 0.000268\n",
      "  Sample (first 5): [-1.57651203e-05 -1.44854063e-02  2.46168836e-04 -1.92183116e-03\n",
      " -1.27128657e-03]\n",
      "\n",
      "Periodic_Rebal:\n",
      "  Shape: (960,)\n",
      "  Has NaN: False\n",
      "  Has Inf: False\n",
      "  Min: -0.039634\n",
      "  Max: 0.058857\n",
      "  Mean: 0.000252\n",
      "  Sample (first 5): [-1.57651203e-05 -1.44854063e-02  2.46168836e-04 -1.92183116e-03\n",
      " -1.27128657e-03]\n",
      "\n",
      "Risk_Parity:\n",
      "  Shape: (960,)\n",
      "  Has NaN: False\n",
      "  Has Inf: False\n",
      "  Min: -0.033092\n",
      "  Max: 0.048289\n",
      "  Mean: 0.000217\n",
      "  Sample (first 5): [-1.57651203e-05 -1.45412379e-02  2.57411254e-04 -1.99207077e-03\n",
      " -1.26437481e-03]\n",
      "\n",
      "Momentum:\n",
      "  Shape: (960,)\n",
      "  Has NaN: False\n",
      "  Has Inf: False\n",
      "  Min: -0.036925\n",
      "  Max: 0.052547\n",
      "  Mean: 0.000197\n",
      "  Sample (first 5): [-1.57651203e-05 -1.45412379e-02  2.57411254e-04 -1.99207077e-03\n",
      " -1.26437481e-03]\n",
      "\n",
      "MeanVar:\n",
      "  Shape: (960,)\n",
      "  Has NaN: False\n",
      "  Has Inf: False\n",
      "  Min: -0.034204\n",
      "  Max: 0.042440\n",
      "  Mean: 0.000126\n",
      "  Sample (first 5): [-1.57651203e-05 -1.45412379e-02  2.57411254e-04 -1.99207077e-03\n",
      " -1.26437481e-03]\n"
     ]
    }
   ],
   "source": [
    "# DIAGNOSTIC: Check baseline results\n",
    "print(\"Checking baseline results...\")\n",
    "for name, results in baseline_results.items():\n",
    "    daily_rets = results['daily_returns']\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  Shape: {daily_rets.shape}\")\n",
    "    print(f\"  Has NaN: {np.isnan(daily_rets).any()}\")\n",
    "    print(f\"  Has Inf: {np.isinf(daily_rets).any()}\")\n",
    "    print(f\"  Min: {np.min(daily_rets):.6f}\")\n",
    "    print(f\"  Max: {np.max(daily_rets):.6f}\")\n",
    "    print(f\"  Mean: {np.mean(daily_rets):.6f}\")\n",
    "    print(f\"  Sample (first 5): {daily_rets[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed47cd8",
   "metadata": {},
   "source": [
    "## 10. Statistical Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61db74ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STATISTICAL TESTS\n",
      "================================================================================\n",
      "\n",
      "1. Diebold-Mariano Test: PPO_RL vs EW_BuyHold\n",
      "  DM_statistic: 1.1828749487168468\n",
      "  p_value: 0.236858711280155\n",
      "  mean_loss_diff: 9.988915137004086e-05\n",
      "  interpretation: X better than Y\n",
      "\n",
      "2. Block Bootstrap 95% CI for PPO_RL Sharpe\n",
      "  observed_sharpe: 0.3284\n",
      "  ci_lower_95: -0.6454\n",
      "  ci_upper_95: 1.4109\n",
      "  bootstrap_mean: 0.3823\n",
      "  bootstrap_std: 0.5282\n"
     ]
    }
   ],
   "source": [
    "from metrics.tests import diebold_mariano, sharpe_block_bootstrap\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STATISTICAL TESTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. Diebold-Mariano: RL vs best baseline\n",
    "best_baseline = df_metrics.drop('PPO_RL').sort_values('Sharpe', ascending=False).index[0]\n",
    "print(f\"\\n1. Diebold-Mariano Test: PPO_RL vs {best_baseline}\")\n",
    "\n",
    "dm_result = diebold_mariano(\n",
    "    rl_results['daily_returns'],\n",
    "    all_results[best_baseline]['daily_returns'],\n",
    "    loss='neg_return'\n",
    ")\n",
    "\n",
    "for key, value in dm_result.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# 2. Block Bootstrap CI for RL Sharpe\n",
    "print(\"\\n2. Block Bootstrap 95% CI for PPO_RL Sharpe\")\n",
    "boot_result = sharpe_block_bootstrap(rl_results['daily_returns'], block=20, reps=5000)\n",
    "\n",
    "for key, value in boot_result.items():\n",
    "    if isinstance(value, (int, float)):\n",
    "        print(f\"  {key}: {value:.4f}\")\n",
    "    else:\n",
    "        print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99452cbc",
   "metadata": {},
   "source": [
    "## 11. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74cdedf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating plots...\n",
      "Saved comparison plot to ../figures/equity_curves_comparison.png\n",
      "Saved equity plot to ../figures/rl_equity_curve.png\n",
      "Saved rolling Sharpe plot to ../figures/rl_rolling_sharpe.png\n",
      "Saved drawdown plot to ../figures/rl_drawdown.png\n",
      "Saved weights heatmap to ../figures/rl_weights_heatmap.png\n",
      "Saved weights area plot to ../figures/rl_weights_area.png\n",
      "Saved weight statistics plot to ../figures/rl_weight_stats.png\n",
      "Saved turnover vs sharpe plot to ../figures/turnover_vs_sharpe.png\n",
      "\n",
      "All plots saved to figures/ directory!\n"
     ]
    }
   ],
   "source": [
    "from plots.equity import plot_multiple_equity_curves, plot_equity_curve\n",
    "from plots.rolling import plot_rolling_sharpe, plot_drawdown\n",
    "from plots.weights import plot_weights_heatmap, plot_weights_area, plot_weight_statistics\n",
    "from plots.sensitivity import plot_turnover_vs_sharpe\n",
    "\n",
    "print(\"Generating plots...\")\n",
    "\n",
    "# 1. Multiple equity curves\n",
    "plot_multiple_equity_curves(\n",
    "    all_results,\n",
    "    title=\"Strategy Comparison: Equity Curves (Test Set)\",\n",
    "    savepath=\"../figures/equity_curves_comparison.png\"\n",
    ")\n",
    "\n",
    "# 2. RL equity curve with drawdown\n",
    "plot_equity_curve(\n",
    "    rl_results['daily_returns'],\n",
    "    title=\"PPO RL Agent: Equity Curve\",\n",
    "    savepath=\"../figures/rl_equity_curve.png\",\n",
    "    dates=dates_test\n",
    ")\n",
    "\n",
    "# 3. Rolling Sharpe\n",
    "plot_rolling_sharpe(\n",
    "    rl_results['daily_returns'],\n",
    "    window=63,\n",
    "    savepath=\"../figures/rl_rolling_sharpe.png\",\n",
    "    dates=dates_test\n",
    ")\n",
    "\n",
    "# 4. Drawdown\n",
    "plot_drawdown(\n",
    "    rl_results['daily_returns'],\n",
    "    savepath=\"../figures/rl_drawdown.png\",\n",
    "    dates=dates_test\n",
    ")\n",
    "\n",
    "# 5. Weights heatmap\n",
    "plot_weights_heatmap(\n",
    "    rl_results['weights'],\n",
    "    config['assets'],\n",
    "    savepath=\"../figures/rl_weights_heatmap.png\"\n",
    ")\n",
    "\n",
    "# 6. Weights area chart\n",
    "plot_weights_area(\n",
    "    rl_results['weights'],\n",
    "    config['assets'],\n",
    "    savepath=\"../figures/rl_weights_area.png\"\n",
    ")\n",
    "\n",
    "# 7. Weight statistics\n",
    "plot_weight_statistics(\n",
    "    rl_results['weights'],\n",
    "    config['assets'],\n",
    "    savepath=\"../figures/rl_weight_stats.png\"\n",
    ")\n",
    "\n",
    "# 8. Turnover vs Sharpe\n",
    "plot_turnover_vs_sharpe(\n",
    "    all_results,\n",
    "    savepath=\"../figures/turnover_vs_sharpe.png\"\n",
    ")\n",
    "\n",
    "print(\"\\nAll plots saved to figures/ directory!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049febac",
   "metadata": {},
   "source": [
    "## 12. Sensitivity Analysis: Transaction Cost Sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b411253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SENSITIVITY ANALYSIS: TRANSACTION COST SWEEP\n",
      "================================================================================\n",
      "\n",
      "Testing cost = 0 bps...\n",
      "\n",
      "Testing cost = 5 bps...\n",
      "\n",
      "Testing cost = 10 bps...\n",
      "\n",
      "Testing cost = 20 bps...\n",
      "\n",
      "Testing cost = 30 bps...\n",
      "\n",
      "Testing cost = 50 bps...\n",
      "\n",
      "Cost Sweep Results:\n",
      "strategy  EW_BuyHold  MeanVar  Momentum  PPO_RL  Periodic_Rebal  Risk_Parity\n",
      "cost_bps                                                                    \n",
      "0              0.549    0.312     0.473   0.534           0.510        0.515\n",
      "5              0.549    0.307     0.459   0.493           0.510        0.509\n",
      "10             0.549    0.301     0.444   0.452           0.509        0.503\n",
      "20             0.549    0.291     0.415   0.369           0.508        0.491\n",
      "30             0.549    0.281     0.386   0.287           0.507        0.478\n",
      "50             0.549    0.260     0.328   0.123           0.504        0.454\n",
      "Saved cost sweep plot to ../figures/cost_sensitivity.png\n",
      "\n",
      "Cost sensitivity plot saved!\n"
     ]
    }
   ],
   "source": [
    "from plots.sensitivity import plot_cost_sweep\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SENSITIVITY ANALYSIS: TRANSACTION COST SWEEP\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "cost_sweep_values = [0, 5, 10, 20, 30, 50]  # bps per turnover\n",
    "cost_sweep_results = []\n",
    "\n",
    "for cost_bps in cost_sweep_values:\n",
    "    print(f\"\\nTesting cost = {cost_bps} bps...\")\n",
    "    \n",
    "    # Update config\n",
    "    config_sweep = config.copy()\n",
    "    config_sweep['trade']['cost_bps_per_turnover'] = cost_bps\n",
    "    \n",
    "    # Re-run strategies (using cached weights, just recompute returns with new cost)\n",
    "    for strategy_name, cached_results in all_results.items():\n",
    "        weights = cached_results['weights']\n",
    "        turnover = cached_results['turnover']\n",
    "        \n",
    "        # Recompute with new cost\n",
    "        cost_rate = cost_bps / 10000.0\n",
    "        costs = turnover * cost_rate\n",
    "        \n",
    "        # Recompute net returns\n",
    "        daily_returns = []\n",
    "        for t in range(len(turnover)):\n",
    "            gross_ret = np.dot(weights[t], R_test[t])\n",
    "            net_ret = gross_ret - costs[t]\n",
    "            daily_returns.append(net_ret)\n",
    "        \n",
    "        daily_returns = np.array(daily_returns)\n",
    "        sharpe = (np.mean(daily_returns) / (np.std(daily_returns, ddof=1) + 1e-10)) * np.sqrt(252)\n",
    "        \n",
    "        cost_sweep_results.append({\n",
    "            'cost_bps': cost_bps,\n",
    "            'strategy': strategy_name,\n",
    "            'sharpe': sharpe\n",
    "        })\n",
    "\n",
    "df_cost_sweep = pd.DataFrame(cost_sweep_results)\n",
    "print(\"\\nCost Sweep Results:\")\n",
    "print(df_cost_sweep.pivot(index='cost_bps', columns='strategy', values='sharpe').round(3))\n",
    "\n",
    "# Plot\n",
    "plot_cost_sweep(df_cost_sweep, savepath=\"../figures/cost_sensitivity.png\")\n",
    "print(\"\\nCost sensitivity plot saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef3dec6",
   "metadata": {},
   "source": [
    "## 13. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f915b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "EXPORTING RESULTS\n",
      "================================================================================\n",
      "\n",
      "1. Saved: results/test_daily_returns.csv\n",
      "2. Saved: results/test_weights_rl.csv\n",
      "3. Saved: results/artifacts.json\n",
      "\n",
      "================================================================================\n",
      "ALL DONE! ðŸŽ‰\n",
      "================================================================================\n",
      "\n",
      "Results saved to:\n",
      "  - results/test_daily_returns.csv\n",
      "  - results/test_weights_rl.csv\n",
      "  - results/test_performance_summary.csv\n",
      "  - results/artifacts.json\n",
      "\n",
      "Figures saved to:\n",
      "  - figures/equity_curves_comparison.png\n",
      "  - figures/rl_*.png (various plots)\n",
      "  - figures/cost_sensitivity.png\n",
      "\n",
      "Best model saved to:\n",
      "  - ../results/logs/ppo\\best_model_sharpe_1.3160.zip\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EXPORTING RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Get the actual number of returns (should be 960)\n",
    "n_returns = len(rl_results['daily_returns'])\n",
    "\n",
    "# 1. Daily returns - slice dates to match returns length\n",
    "df_returns = pd.DataFrame({\n",
    "    name: results['daily_returns'] \n",
    "    for name, results in all_results.items()\n",
    "}, index=dates_test[:n_returns])\n",
    "df_returns.to_csv('../results/test_daily_returns.csv')\n",
    "print(\"\\n1. Saved: results/test_daily_returns.csv\")\n",
    "\n",
    "# 2. Weights (RL only) - slice dates to match weights length\n",
    "df_weights = pd.DataFrame(\n",
    "    rl_results['weights'],\n",
    "    columns=config['assets'],\n",
    "    index=dates_test[:n_returns]\n",
    ")\n",
    "df_weights.to_csv('../results/test_weights_rl.csv')\n",
    "print(\"2. Saved: results/test_weights_rl.csv\")\n",
    "\n",
    "# 3. Artifacts metadata\n",
    "artifacts = {\n",
    "    'config': config,\n",
    "    'metrics_summary': df_metrics.to_dict(),\n",
    "    'dm_test': dm_result,\n",
    "    'bootstrap_ci': boot_result,\n",
    "    'library_versions': {\n",
    "        'numpy': np.__version__,\n",
    "        'pandas': pd.__version__,\n",
    "    }\n",
    "}\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    artifacts['library_versions']['torch'] = torch.__version__\n",
    "except:\n",
    "    pass\n",
    "\n",
    "with open('../results/artifacts.json', 'w') as f:\n",
    "    json.dump(artifacts, f, indent=2, default=str)\n",
    "print(\"3. Saved: results/artifacts.json\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ALL DONE! ðŸŽ‰\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nResults saved to:\")\n",
    "print(\"  - results/test_daily_returns.csv\")\n",
    "print(\"  - results/test_weights_rl.csv\")\n",
    "print(\"  - results/test_performance_summary.csv\")\n",
    "print(\"  - results/artifacts.json\")\n",
    "print(\"\\nFigures saved to:\")\n",
    "print(\"  - figures/equity_curves_comparison.png\")\n",
    "print(\"  - figures/rl_*.png (various plots)\")\n",
    "print(\"  - figures/cost_sensitivity.png\")\n",
    "print(\"\\nBest model saved to:\")\n",
    "print(f\"  - {best_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff177392-4ac4-41d7-bede-9ca3b42e0651",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
